{
  "name": "@khanglvm/llm-router",
  "version": "1.0.6",
  "description": "Single gateway endpoint for multi-provider LLMs with unified OpenAI+Anthropic format and seamless fallback",
  "type": "module",
  "main": "src/index.js",
  "bin": {
    "llm-router": "./src/cli-entry.js",
    "llm-router-route": "./src/cli-entry.js"
  },
  "scripts": {
    "dev": "wrangler dev",
    "deploy": "wrangler deploy",
    "tail": "wrangler tail",
    "start": "node ./src/cli-entry.js start",
    "config": "node ./src/cli-entry.js config",
    "deploy:worker": "node ./src/cli-entry.js deploy",
    "test:provider-smoke": "node ./scripts/provider-smoke-suite.mjs"
  },
  "dependencies": {
    "@levu/snap": "^0.3.11"
  },
  "devDependencies": {
    "wrangler": "^4.68.1"
  },
  "publishConfig": {
    "access": "public"
  },
  "files": [
    "src/**/*.js",
    "!src/**/*.test.js",
    "!src/**/*.spec.js",
    "README.md",
    "SECURITY.md",
    "CHANGELOG.md",
    "wrangler.toml"
  ]
}
